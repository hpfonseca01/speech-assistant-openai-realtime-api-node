import Fastify from 'fastify';
import WebSocket from 'ws';
import dotenv from 'dotenv';
import fastifyFormBody from '@fastify/formbody';
import fastifyWs from '@fastify/websocket';

// Load environment variables from .env file
dotenv.config();

// Retrieve the OpenAI API key from environment variables.
const { OPENAI_API_KEY } = process.env;

if (!OPENAI_API_KEY) {
    console.error('Missing OpenAI API key. Please set it in the .env file.');
    process.exit(1);
}

// Initialize Fastify
const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);

// DADOS DE TESTE - Hardcoded
const DADOS_CLIENTE_TESTE = {
    nome: 'Paulo Godoy',
    valor: '1.500,00',
    empresa: 'Poderoso TimÃ£o',
    data: '15/11/2024',
    contrato: 'CTR-2024-001'
};

// Constants
const SYSTEM_MESSAGE = `VocÃª Ã© Lucas, um agente de cobranÃ§a profissional da empresa Ã“los Tecnologia.

=== IDENTIDADE E TOM ===
- Nome: Lucas
- Empresa: Ã“los Tecnologia
- Tom: Profissional, educado, firme mas respeitoso
- Objetivo: Resolver a situaÃ§Ã£o da dÃ­vida de forma amigÃ¡vel
- Idioma: PortuguÃªs brasileiro natural e claro

=== INFORMAÃ‡Ã•ES DO CLIENTE (IMPORTANTE - USE EXATAMENTE ESSES DADOS) ===
- Nome do Cliente: ${DADOS_CLIENTE_TESTE.nome}
- Valor da DÃ­vida: R$ ${DADOS_CLIENTE_TESTE.valor}
- Empresa Credora: ${DADOS_CLIENTE_TESTE.empresa}
- Data de Vencimento: ${DADOS_CLIENTE_TESTE.data}
- NÃºmero do Contrato: ${DADOS_CLIENTE_TESTE.contrato}

=== INFORMAÃ‡Ã•ES QUE VOCÃŠ CONHECE ===
(Estas informaÃ§Ãµes serÃ£o fornecidas no inÃ­cio da ligaÃ§Ã£o)
- Nome completo do devedor
- Valor da dÃ­vida
- Data de vencimento original
- Empresa credora
- NÃºmero do contrato/boleto

=== SCRIPT DE COBRANÃ‡A (SIGA ESTA ORDEM) ===

1. ABERTURA (IdentificaÃ§Ã£o)
   "Bom dia/Boa tarde, meu nome Ã© Lucas da Olos CobranÃ§as. Estou falando com ${DADOS_CLIENTE_TESTE.nome}?"
   
   Aguarde confirmaÃ§Ã£o.
   Caso o usuario nÃ£o seja o cliente mas o conheÃ§a, peÃ§a para ligar mais tarde. 
   Caso o usuario nÃ£o seja o cliente e nem o conheÃ§a, peÃ§a desculpas pelo transtorno.
   
   "Perfeito. ${DADOS_CLIENTE_TESTE.nome}, estou ligando em nome de ${DADOS_CLIENTE_TESTE.empresa} sobre o dÃ©bito no valor de R$ ${DADOS_CLIENTE_TESTE.valor} com vencimento em ${DADOS_CLIENTE_TESTE.data}, contrato nÃºmero ${DADOS_CLIENTE_TESTE.contrato}. VocÃª tem conhecimento deste dÃ©bito?"

2. CONFIRMAÃ‡ÃƒO E ESCUTA
   - Se SIM: Prossiga para negociaÃ§Ã£o
   - Se NÃƒO: Explique detalhes (empresa, valor, data, nÃºmero do contrato)
   - IMPORTANTE: OuÃ§a a situaÃ§Ã£o do cliente com empatia

3. INVESTIGAÃ‡ÃƒO DA SITUAÃ‡ÃƒO
   "Entendo. Poderia me explicar o que aconteceu para nÃ£o ter sido possÃ­vel realizar o pagamento?"
   
   OuÃ§a atentamente e demonstre empatia:
   - "Entendo sua situaÃ§Ã£o"
   - "Compreendo que esse momento Ã© difÃ­cil"
   - "Vamos encontrar uma soluÃ§Ã£o juntos"

4. APRESENTAR OPÃ‡Ã•ES (NA ORDEM)

   OPÃ‡ÃƒO A - Pagamento Integral:
    "VocÃª conseguiria realizar o pagamento integral de R$ ${DADOS_CLIENTE_TESTE.valor} atÃ© amanhÃ£?"
   
   OPÃ‡ÃƒO B - Parcelamento:
   "Caso nÃ£o seja possÃ­vel o pagamento integral, posso oferecer um parcelamento. VocÃª preferiria pagar em quantas vezes? Temos opÃ§Ãµes de 2x, 3x ou atÃ© 6x."
   
   OPÃ‡ÃƒO C - Entrada + Parcelamento:
   "Outra opÃ§Ã£o Ã© fazer uma entrada de R$ [VALOR_ENTRADA] hoje e parcelar o restante em [X] vezes de R$ [VALOR_PARCELA]. Isso ficaria bom para vocÃª?"
   
   OPÃ‡ÃƒO D - Data Futura:
   "Se nenhuma dessas opÃ§Ãµes for viÃ¡vel agora, em qual data vocÃª conseguiria fazer o pagamento? Posso agendar para uma data especÃ­fica."

5. FECHAR ACORDO
   Quando o cliente aceitar uma opÃ§Ã£o:
   
   "Perfeito! Vou confirmar entÃ£o: vocÃª vai realizar o pagamento de R$ [VALOR] atÃ© [DATA] / em [X] parcelas de R$ [VALOR]. EstÃ¡ correto?"
   
   "Ã“timo! Vou enviar os dados para pagamento via [WhatsApp/Email/SMS]. Qual o melhor contato?"
   
   "Confirmo entÃ£o seu [WhatsApp/Email]: [CONTATO]. Os dados chegarÃ£o em atÃ© 5 minutos."

6. ENCERRAMENTO
   "AgradeÃ§o sua atenÃ§Ã£o, [NOME]. Caso tenha qualquer dÃºvida, pode entrar em contato conosco. Tenha um Ã³timo dia!"

=== REGRAS OBRIGATÃ“RIAS ===

âœ… SEMPRE FAZER:
- Ser educado e respeitoso, independente da reaÃ§Ã£o do cliente
- Confirmar informaÃ§Ãµes importantes (valores, datas)
- Oferecer opÃ§Ãµes de pagamento
- Anotar compromissos assumidos
- Agradecer ao final

âŒ NUNCA FAZER:
- Ser agressivo, ameaÃ§ador ou desrespeitoso
- Ligar antes das 8h ou depois das 20h (mesmo que o cliente ligue)
- Fazer ameaÃ§as de protesto, SPC, ou processos judiciais
- Expor a situaÃ§Ã£o para terceiros
- Insistir excessivamente se o cliente pedir para nÃ£o ligar mais
- Gravar ou mencionar que estÃ¡ gravando sem autorizaÃ§Ã£o
- Usar palavras como "inadimplente", "caloteiro", "devedor"

=== OBJEÃ‡Ã•ES COMUNS E RESPOSTAS ===

Cliente: "NÃ£o tenho dinheiro agora"
VocÃª: "Entendo perfeitamente. Por isso mesmo estou oferecendo opÃ§Ãµes flexÃ­veis. Qual valor vocÃª conseguiria pagar como entrada? Podemos comeÃ§ar com um valor menor."

Cliente: "Vou pagar depois"
VocÃª: "Ã“timo! Para formalizar isso, qual data especÃ­fica vocÃª consegue se comprometer? Assim eu jÃ¡ agendo aqui e nÃ£o preciso incomodÃ¡-lo novamente."

Cliente: "JÃ¡ paguei"
VocÃª: "Perfeito! VocÃª teria o comprovante? Posso aguardar enquanto vocÃª busca para confirmarmos aqui no sistema."

Cliente: "Essa dÃ­vida nÃ£o Ã© minha"
VocÃª: "Entendo sua preocupaÃ§Ã£o. Vou anotar sua contestaÃ§Ã£o. Poderia me confirmar seus dados para verificarmos? [Nome completo, CPF, endereÃ§o]"

Cliente: "NÃ£o posso falar agora"
VocÃª: "Sem problemas! Qual horÃ¡rio seria melhor para retornar a ligaÃ§Ã£o? ManhÃ£ ou tarde?"

Cliente: "Parem de me ligar"
VocÃª: "Entendo. Para que eu possa registrar aqui, vocÃª estÃ¡ se negando a negociar o dÃ©bito? Neste caso, vou anotar e a cobranÃ§a seguirÃ¡ por outros canais. Posso confirmar?"

=== INFORMAÃ‡Ã•ES DE COMPLIANCE ===

VocÃª estÃ¡ ciente que:
- Esta ligaÃ§Ã£o pode estar sendo gravada para fins de qualidade
- VocÃª deve respeitar o CÃ³digo de Defesa do Consumidor
- VocÃª nÃ£o pode fazer cobranÃ§as vexatÃ³rias
- VocÃª deve ser transparente sobre a dÃ­vida

=== FORMATO DE RESPOSTA ===

- Fale de forma NATURAL e CONVERSACIONAL
- Use frases CURTAS (mÃ¡ximo 2-3 linhas por vez)
- AGUARDE resposta do cliente antes de continuar
- NÃƒO fale rÃ¡pido demais
- REPITA informaÃ§Ãµes importantes se necessÃ¡rio
- Se o cliente interromper, PARE e escute

=== FINALIZAÃ‡ÃƒO ===

Quando o acordo for fechado, use a seguinte funÃ§Ã£o para registrar:
- Valor acordado
- Forma de pagamento
- Data do pagamento
- Contato do cliente

Mantenha sempre o profissionalismo e lembre-se: seu objetivo Ã© RESOLVER, nÃ£o apenas cobrar.`;
const VOICE = 'ballad';
const TEMPERATURE = 0.6; // Controls the randomness of the AI's responses
const PORT = process.env.PORT || 5050; // Allow dynamic port assignment

// List of Event Types to log to the console. See the OpenAI Realtime API Documentation: https://platform.openai.com/docs/api-reference/realtime
const LOG_EVENT_TYPES = [
    'error',
    'response.content.done',
    'rate_limits.updated',
    'response.done',
    'input_audio_buffer.committed',
    'input_audio_buffer.speech_stopped',
    'input_audio_buffer.speech_started',
    'session.created',
    'session.updated'
];

// Show AI response elapsed timing calculations
const SHOW_TIMING_MATH = false;

import fs from 'fs';
import path from 'path';

// FunÃ§Ã£o para salvar tabulaÃ§Ã£o
function salvarTabulacao(dados) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `tabulacao_${timestamp}.json`;
    const filepath = path.join('/tmp', filename);
    
    try {
        fs.writeFileSync(filepath, JSON.stringify(dados, null, 2));
        console.log('âœ… TabulaÃ§Ã£o salva:', filename);
        return filepath;
    } catch (error) {
        console.error('âŒ Erro ao salvar:', error);
        return null;
    }
}

// Root Route
fastify.get('/', async (request, reply) => {
    reply.send({ message: 'Twilio Media Stream Server is running!' });
});

// Route for Twilio to handle incoming calls
// <Say> punctuation to improve text-to-speech translation
fastify.all('/incoming-call', async (request, reply) => {
    const twimlResponse = `<?xml version="1.0" encoding="UTF-8"?>
                          <Response>
                              <Say voice="Polly.Camila" language="pt-BR">OlÃ¡! Aguarde enquanto conectamos vocÃª com nosso assistente virtual da Olos.</Say>
                              <Pause length="1"/>
                              <Say voice="Polly.Camila" language="pt-BR">Pode falar!</Say>
                              <Connect>
                                  <Stream url="wss://${request.headers.host}/media-stream" />
                              </Connect>
                          </Response>`;

    reply.type('text/xml').send(twimlResponse);
});

// WebSocket route for media-stream
fastify.register(async (fastify) => {
    fastify.get('/media-stream', { websocket: true }, (connection, req) => {
        console.log('Client connected');
        
// ========================================
        // ðŸ“Š DADOS PARA TABULAÃ‡ÃƒO
        // ========================================
        let dadosChamada = {
            inicio: new Date().toISOString(),
            fim: null,
            duracao_segundos: 0,
            cliente: {
                nome: DADOS_CLIENTE_TESTE.nome,
                valor_divida: DADOS_CLIENTE_TESTE.valor,
                empresa: DADOS_CLIENTE_TESTE.empresa,
                data_vencimento: DADOS_CLIENTE_TESTE.data,
                contrato: DADOS_CLIENTE_TESTE.contrato
            },
            resultado: 'em_andamento',
            acordo: null,
            observacoes: '',
            transcricao: []
        };
        
        let callSid = null;
        
        // Connection-specific state
        let streamSid = null;
        let latestMediaTimestamp = 0;
        let lastAssistantItem = null;
        let markQueue = [];
        let responseStartTimestampTwilio = null;

        const openAiWs = new WebSocket(`wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01&temperature=${TEMPERATURE}`, {
            headers: {
                Authorization: `Bearer ${OPENAI_API_KEY}`,
            }
        });

        // Control initial session with OpenAI
        const initializeSession = () => {
            const sessionUpdate = {
                type: 'session.update',
                session: {
                    type: 'realtime',
                    model: "gpt-4o-realtime-preview-2024-10-01",
                    output_modalities: ["audio"],
                    audio: {
                        input: { format: { type: 'audio/pcmu' }, turn_detection: { type: "server_vad" } },
                        output: { format: { type: 'audio/pcmu' }, voice: VOICE },
                    },
                    instructions: SYSTEM_MESSAGE,
                },
            };

            console.log('Sending session update:', JSON.stringify(sessionUpdate));
            openAiWs.send(JSON.stringify(sessionUpdate));

            // Uncomment the following line to have AI speak first:
        //sendInitialConversationItem();
        };

        // Send initial conversation item if AI talks first
        const sendInitialConversationItem = () => {
    const initialConversationItem = {
        type: 'conversation.item.create',
        item: {
            type: 'message',
            role: 'user',
            content: [
                {
                    type: 'input_text',
                    text: 'Diga: Oi, tudo bem? sou uma agente speetch to speetch da Olos. Como posso ajudar vocÃª hoje?'
                }
            ]
        }
    };

            if (SHOW_TIMING_MATH) console.log('Sending initial conversation item:', JSON.stringify(initialConversationItem));
            openAiWs.send(JSON.stringify(initialConversationItem));
            openAiWs.send(JSON.stringify({ type: 'response.create' }));
        };

        // Handle interruption when the caller's speech starts
        const handleSpeechStartedEvent = () => {
            if (markQueue.length > 0 && responseStartTimestampTwilio != null) {
                const elapsedTime = latestMediaTimestamp - responseStartTimestampTwilio;
                if (SHOW_TIMING_MATH) console.log(`Calculating elapsed time for truncation: ${latestMediaTimestamp} - ${responseStartTimestampTwilio} = ${elapsedTime}ms`);

                if (lastAssistantItem) {
                    const truncateEvent = {
                        type: 'conversation.item.truncate',
                        item_id: lastAssistantItem,
                        content_index: 0,
                        audio_end_ms: elapsedTime
                    };
                    if (SHOW_TIMING_MATH) console.log('Sending truncation event:', JSON.stringify(truncateEvent));
                    openAiWs.send(JSON.stringify(truncateEvent));
                }

                connection.send(JSON.stringify({
                    event: 'clear',
                    streamSid: streamSid
                }));

                // Reset
                markQueue = [];
                lastAssistantItem = null;
                responseStartTimestampTwilio = null;
            }
        };

        // Send mark messages to Media Streams so we know if and when AI response playback is finished
        const sendMark = (connection, streamSid) => {
            if (streamSid) {
                const markEvent = {
                    event: 'mark',
                    streamSid: streamSid,
                    mark: { name: 'responsePart' }
                };
                connection.send(JSON.stringify(markEvent));
                markQueue.push('responsePart');
            }
        };

        // Open event for OpenAI WebSocket
        openAiWs.on('open', () => {
            console.log('Connected to the OpenAI Realtime API');
            setTimeout(initializeSession, 100);
        });

        // Listen for messages from the OpenAI WebSocket (and send to Twilio if necessary)
        openAiWs.on('message', (data) => {
            try {
                const response = JSON.parse(data);

                if (LOG_EVENT_TYPES.includes(response.type)) {
                    console.log(`Received event: ${response.type}`, response);
                }

                if (response.type === 'response.output_audio.delta' && response.delta) {
                    const audioDelta = {
                        event: 'media',
                        streamSid: streamSid,
                        media: { payload: response.delta }
                    };
                    connection.send(JSON.stringify(audioDelta));

                    // First delta from a new response starts the elapsed time counter
                    if (!responseStartTimestampTwilio) {
                        responseStartTimestampTwilio = latestMediaTimestamp;
                        if (SHOW_TIMING_MATH) console.log(`Setting start timestamp for new response: ${responseStartTimestampTwilio}ms`);
                    }

                    if (response.item_id) {
                        lastAssistantItem = response.item_id;
                    }
                    
                    sendMark(connection, streamSid);
                }

                if (response.type === 'input_audio_buffer.speech_started') {
                    handleSpeechStartedEvent();
                }
            } catch (error) {
                console.error('Error processing OpenAI message:', error, 'Raw message:', data);
            }
        });

        // Handle incoming messages from Twilio
        connection.on('message', (message) => {
            try {
                const data = JSON.parse(message);

                switch (data.event) {
                    case 'media':
                        latestMediaTimestamp = data.media.timestamp;
                        if (SHOW_TIMING_MATH) console.log(`Received media message with timestamp: ${latestMediaTimestamp}ms`);
                        if (openAiWs.readyState === WebSocket.OPEN) {
                            const audioAppend = {
                                type: 'input_audio_buffer.append',
                                audio: data.media.payload
                            };
                            openAiWs.send(JSON.stringify(audioAppend));
                        }
                        break;
                    case 'start':
                        streamSid = data.start.streamSid;
                        console.log('Incoming stream has started', streamSid);
                        callSid = data.start.callSid;
console.log('Call SID:', callSid);

                        // Reset start and media timestamp on a new stream
                        responseStartTimestampTwilio = null; 
                        latestMediaTimestamp = 0;
                        break;
                    case 'mark':
                        if (markQueue.length > 0) {
                            markQueue.shift();
                        }
                        break;
                    default:
                        console.log('Received non-media event:', data.event);
                        break;
                }
            } catch (error) {
                console.error('Error parsing message:', error, 'Message:', message);
            }
        });

        // Handle connection close
        connection.on('close', () => {
            // ========================================
        // ðŸ“Š SALVAR TABULAÃ‡ÃƒO DA CHAMADA
        // ========================================
        const fim = new Date();
        const inicio = new Date(dadosChamada.inicio);
        dadosChamada.fim = fim.toISOString();
        dadosChamada.duracao_segundos = Math.floor((fim - inicio) / 1000);
        dadosChamada.callSid = callSid;
        dadosChamada.streamSid = streamSid;
        
        // SALVAR
        salvarTabulacao(dadosChamada);
        // ========================================
            if (openAiWs.readyState === WebSocket.OPEN) openAiWs.close();
            console.log('Client disconnected.');
        });

        // Handle WebSocket close and errors
        openAiWs.on('close', () => {
            console.log('Disconnected from the OpenAI Realtime API');
        });

        openAiWs.on('error', (error) => {
            console.error('Error in the OpenAI WebSocket:', error);
        });
    });
});

fastify.listen({ port: PORT, host: '0.0.0.0' }, (err, address) => {
    if (err) {
        console.error(err);
        process.exit(1);
    }
    console.log(`Server is listening on port ${PORT}`);
});
